{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo3sAoUGGOzb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KcNcd6bTlzR"
      },
      "source": [
        "\n",
        "\n",
        "#documents = ['This certify that Mr Anand J Kulkarni, Symbiosis International University, Pune , India has conducted a tutorial session titled \"Cohort Intelligence Algorithm\" at MIT, Pune',\n",
        " #            'This certify that Mrs Rupali has attended a two days FDP session on \"AI with Health caree\" at SIT, Pune',\n",
        "  #           'This certify that Mr Sanjay M J, has conducted a tutorial session titled \"Deep Adaptive Learning\" at VIIT, chennai',\n",
        "   #          'This certify that Mrs Ambika Pawar, has attended a FDP workshop on \"Big Data using Hadoop\" at SIT, Pune',\n",
        "    #         'This certify that Mrs Rutuja, has attended a FDP workshop on \"Big Data using Hadoop\" at SIT, Pune',\n",
        "     #        'This certify that Ms Krithika, has attended a FDP workshop on \"Machine Learning\" at SIT, Pune',\n",
        "     #        'This certify that Mrs Saloni has attended a two days FDP session on \"Incremental Clustering\" at MIT, Pune',\n",
        "      #        'This certify that Mrs Ayushi has attended a two days FDP session on \"Incremental Learning\" at MIT, Pune',\n",
        "       #       'This certify that Mrs Preeti has attended a two days FDP session on \"Incremental Clustering using Deep Learning\" at VIIT, chennai',\n",
        "        #      'This certify that Mrs Saloni has attended a two days FDP session on \"Incremental Clustering\" at VIIT, chennai',\n",
        "         #     'This certify that Mrs Krithika has attended a two days FDP session on \"Distributed System\" at MIT, Pune']\n",
        "\n",
        "\n",
        "documents = ['Re-accredited by NAAC with k’ grade (3.58/4) | Awarded Category - Iby UGC\\n\\nFaculty Development Programme\\n\\n‘This is to certify that Mr./Ms./Dr.\\n\\n \\n\\n \\n\\nof biosis Institute of Technolo participated\\nin one day workshop on “ Research Opportunities in Health Care: How your work can save millions of lives\\nand billions of $ in health sector” organized by Symbiosis Teaching Learning Resource Centre, STU,\\n\\non 21 July 2018.\\n\\nshud\\nPlace : Pune. Dr. Kone\\n\\nDate : July 21, 2018 rereren Registrar, SIU\\n1U\\n\\x0c',\n",
        "            'Faculty Development Programme\\n\\nThis is to certify that Mr./Ms./Dr.\\nof\\nin Half day Preconference Tutorial on * Healthcare and Wellness ” organized by Symbiosis Teaching\\n\\n \\n\\n \\n\\nparticipated\\n\\n \\n\\nLearning Resource Centre, on 30 November 2\\n\\nPlace : Pune. & Dr. wl Sh \\\\\\nDate : November 30, 2018 tetra SIU\\n\\nSTU Resistrar, SIU\\n\\x0c',\n",
        "             'EEE nn ere nT Ten ET\\n\\nFaculty Development Programme\\n\\nThis is to certify that Mr./Ms./Dr.\\n\\n \\n\\n \\n\\nof mbiosis Insti participated\\nin two days workshop on “ Tapping the Suns Solar Energy for Electricity Needs of Mankind” organized\\nby Symbiosis Teaching Learning Resource\\n\\n \\n\\nsire, on 24 and 25 August 2018.\\n\\nWhnl\\n\\nEieee=sEune: br. md shop\\nDate : August 25, 2018 stem Registrar, SIU\\n\\n \\n\\nSIU\\n\\x0c'\n",
        "             '\\n\\n‘SrNo.CPN103024\\n\\nROYAL\\nACADEMY OF\\n\\n\\\\/ ENGINEERING\\n\\n    \\n\\nUNIvERS i,\\n\\n \\n\\nUniversity College Lendon —symbigsis Institute of Technology\\n\\nWORKSHOP ON\\n\\nARTIFICIAL INTELLIGENCE AND DEEP LEARNING\\n\\n \\n\\n \\n\\nThis is to certify that Kalyani Kadam\\nhas successfully cleared the assessment test and completed\\na hands on Workshop on Artificial Intelligence and Deep Learning\\nheld at Symbiosis Institute of Technology, Pune from,,June 13,2018 to... 15,2018\\n\\nConducted by leadingIndia.ai, a nation wide initiative by Bennett University,\\nGreater Noida, India\\n\\n \\n\\n       \\n\\ng\\n3\\n3\\n3\\n8\\ny\\n\\x0c']\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODPVbW8Nfs5i",
        "outputId": "445fe69e-06d1-42bf-d790-072fc24f5a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#K MEANS\n",
        "\n",
        "#Count Vectoriser then tidf transformer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents) \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "tfidf = transformer.fit_transform(X)\n",
        "print(tfidf.shape )                        \n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 3 #Change it according to your data.\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(tfidf)\n",
        "clusters = km.labels_.tolist()\n",
        "\n",
        "idea={'Institute':documents, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
        "frame=pd.DataFrame(idea,index=[clusters], columns=['Institute','Cluster']) # Converting it into a dataframe.\n",
        "\n",
        "print(\"\\n\")\n",
        "print(frame) #Print the doc with the labeled cluster number.\n",
        "print(\"\\n\")\n",
        "print(frame['Cluster'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 145)\n",
            "\n",
            "\n",
            "                                           Institute  Cluster\n",
            "2  Re-accredited by NAAC with k’ grade (3.58/4) |...        2\n",
            "1  Faculty Development Programme\\n\\nThis is to ce...        1\n",
            "0  EEE nn ere nT Ten ET\\n\\nFaculty Development Pr...        0\n",
            "\n",
            "\n",
            "2    1\n",
            "1    1\n",
            "0    1\n",
            "Name: Cluster, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms2WTj_80kj9",
        "outputId": "64a0aed4-53b3-40c1-a269-0c15e47b6ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "#K MEANS\n",
        "\n",
        "#Count Vectoriser then tidf transformer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents) \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "tfidf = transformer.fit_transform(X)\n",
        "print(tfidf.shape )                        \n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 3 #Change it according to your data.\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(tfidf)\n",
        "clusters = km.labels_.tolist()\n",
        "\n",
        "idea={'Institute':documents, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
        "frame=pd.DataFrame(idea,index=[clusters], columns=['Institute','Cluster']) # Converting it into a dataframe.\n",
        "\n",
        "print(\"\\n\")\n",
        "print(frame) #Print the doc with the labeled cluster number.\n",
        "print(\"\\n\")\n",
        "print(frame['Cluster'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 57)\n",
            "\n",
            "\n",
            "                                           Institute  Cluster\n",
            "1  This certify that Mr Anand J Kulkarni, Symbios...        1\n",
            "0  This certify that Mrs Rupali has attended a tw...        0\n",
            "1  This certify that Mr Sanjay M J, has conducted...        1\n",
            "2  This certify that Mrs Ambika Pawar, has attend...        2\n",
            "2  This certify that Mrs Rutuja, has attended a F...        2\n",
            "2  This certify that Ms Krithika, has attended a ...        2\n",
            "0  This certify that Mrs Saloni has attended a tw...        0\n",
            "0  This certify that Mrs Ayushi has attended a tw...        0\n",
            "0  This certify that Mrs Preeti has attended a tw...        0\n",
            "0  This certify that Mrs Saloni has attended a tw...        0\n",
            "0  This certify that Mrs Krithika has attended a ...        0\n",
            "\n",
            "\n",
            "0    6\n",
            "2    3\n",
            "1    2\n",
            "Name: Cluster, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaU8rAGtCkSz",
        "outputId": "a401971b-4a7e-4be8-b82c-d39ee954aa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "#DBSCAN\n",
        "\n",
        "# Using the elbow method to find the optimal number of clusters\n",
        "from sklearn.cluster import DBSCAN\n",
        "dbscan=DBSCAN(eps=3,min_samples=3)\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "model=dbscan.fit(tfidf)\n",
        "\n",
        "labels=model.labels_\n",
        "\n",
        "idea={'Institute':documents, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
        "frame=pd.DataFrame(idea,index=[clusters], columns=['Institute','Cluster']) # Converting it into a dataframe.\n",
        "\n",
        "print(\"\\n\")\n",
        "print(frame) #Print the doc with the labeled cluster number.\n",
        "print(\"\\n\")\n",
        "print(frame['Cluster'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "                                           Institute  Cluster\n",
            "1  This certify that Mr Anand J Kulkarni, Symbios...        1\n",
            "0  This certify that Mrs Rupali has attended a tw...        0\n",
            "1  This certify that Mr Sanjay M J, has conducted...        1\n",
            "2  This certify that Mrs Ambika Pawar, has attend...        2\n",
            "2  This certify that Mrs Rutuja, has attended a F...        2\n",
            "2  This certify that Ms Krithika, has attended a ...        2\n",
            "0  This certify that Mrs Saloni has attended a tw...        0\n",
            "0  This certify that Mrs Ayushi has attended a tw...        0\n",
            "0  This certify that Mrs Preeti has attended a tw...        0\n",
            "0  This certify that Mrs Saloni has attended a tw...        0\n",
            "0  This certify that Mrs Krithika has attended a ...        0\n",
            "\n",
            "\n",
            "0    6\n",
            "2    3\n",
            "1    2\n",
            "Name: Cluster, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5woCCcVZ7M86",
        "outputId": "7d0fa8ed-659e-459d-943a-bbd7d0f934bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "#Incremental K means\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "documents = ['This certify that Mr Anand J Kulkarni, Symbiosis International University, Pune , India has conducted a tutorial session titled \"Cohort Intelligence Algorithm\" at MIT, Pune',\n",
        "             'This certify that Mrs Rupali has attended a two days FDP session on \"AI with Health caree\" at SIT, Pune',\n",
        "             'This certify that Mr Sanjay M J, has conducted a tutorial session titled \"Deep Adaptive Learning\" at VIIT, chennai',\n",
        "             'This certify that Mrs Ambika Pawar, has attended a FDP workshop on \"Big Data using Hadoop\" at SIT, Pune',\n",
        "             'This certify that Mrs Rutuja, has attended a FDP workshop on \"Big Data using Hadoop\" at SIT, Pune',\n",
        "             'This certify that Ms Krithika, has attended a FDP workshop on \"Machine Learning\" at SIT, Pune',\n",
        "             'This certify that Mrs Saloni has attended a two days FDP session on \"Incremental Clustering\" at MIT, Pune',\n",
        "              'This certify that Mrs Ayushi has attended a two days FDP session on \"Incremental Learning\" at MIT, Pune',\n",
        "              'This certify that Mrs Preeti has attended a two days FDP session on \"Incremental Clustering using Deep Learning\" at VIIT, chennai',\n",
        "              'This certify that Mrs Saloni has attended a two days FDP session on \"Incremental Clustering\" at VIIT, chennai',\n",
        "              'This certify that Mrs Krithika has attended a two days FDP session on \"Distributed System\" at MIT, Pune']\n",
        "\n",
        "test = ['This certify that Mr Kartik Bhushan has attended a two week FDP session on \"Object Oriented Data Analysis\" at VIIT, Chennai',]\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "#Feature Extraction\n",
        "vectorizer = TfidfVectorizer(min_df = 0, max_df=0.5, stop_words = \"english\",ngram_range = (1,3))\n",
        "vec = vectorizer.fit(documents)\n",
        "vectorized = vec.transform(documents)\n",
        "test_vector = vec.transform(test)\n",
        "\n",
        "minibatchKmeans = MiniBatchKMeans(n_clusters=3,random_state=0,batch_size=6)\n",
        "\n",
        "models = minibatchKmeans.fit(vectorized)\n",
        "\n",
        "labels=models.labels_\n",
        "\n",
        "idea={'Institute':documents, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
        "frame=pd.DataFrame(idea,index=[clusters], columns=['Institute','Cluster']) # Converting it into a dataframe.\n",
        "\n",
        "print(\"\\n\")\n",
        "print(frame) #Print the doc with the labeled cluster number.\n",
        "print(\"\\n\")\n",
        "print(frame['Cluster'].value_counts())\n",
        "\n",
        "minibatchKmeans.predict(test_vector)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6fef7cfb8459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0midea\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Institute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#Creating dict having doc with the corresponding cluster number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midea\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Institute'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Converting it into a dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clusters' is not defined"
          ]
        }
      ]
    }
  ]
}